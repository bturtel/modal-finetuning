{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini Deepseek R1\n",
    "Here we're trying to implement [Mini Deepseek R1](https://www.philschmid.de/mini-deepseek-r1) using Modal.\n",
    "\n",
    "\n",
    "References:\n",
    "- [Mini Deepseek R1](https://www.philschmid.de/mini-deepseek-r1)\n",
    "- [How to Launch a Jupyter Notebook on Modal Programmatically](https://modal.com/blog/how_to_launch_a_jupyter_notebook_on_modal_programmatically_article)\n",
    "- [Modal Examples: Basic Notebook](https://github.com/modal-labs/modal-examples/blob/main/11_notebooks/basic.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTANT: Jupyter notebook local python MUST MATCH the python version in the Modal image.\n",
    "\n",
    "Create a new venv for 3.11:\n",
    "```\n",
    "python3.11 -m venv venv\n",
    "source venv/bin/activate\n",
    "```\n",
    "\n",
    "Copied the Modal image [here](https://github.com/modal-labs/modal-client/blob/d924202767ef313ba67d60451975432e09e7b760/modal/image.py#L962C17-L962C55)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers datasets huggingface_hub jinja2 modal\n",
    "from IPython.display import clear_output\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from the Hugging Face Hub...\n",
      "Dataset loaded. Sample count: 50000\n",
      "Data preprocessing complete. Train size: 45000 Test size: 5000\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "print(\"Loading dataset from the Hugging Face Hub...\")\n",
    "dataset_id = \"Jiayi-Pan/Countdown-Tasks-3to4\"\n",
    "dataset = load_dataset(dataset_id, split=\"train\")\n",
    "\n",
    "# Select a random subset of 50k samples\n",
    "dataset = dataset.shuffle(seed=42).select(range(50000))\n",
    "print(\"Dataset loaded. Sample count:\", len(dataset))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-3B-Instruct\")\n",
    "\n",
    "def generate_r1_prompt(example):\n",
    "    r1_prefix = [\n",
    "      {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant. You first thinks about the reasoning process in your mind and then provides the user with the answer.\"\n",
    "      },\n",
    "      { \n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Using the numbers {example['nums']}, create an equation that equals {example['target']}. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final equation and answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 = 1 </answer>.\"\n",
    "      },\n",
    "      {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Let me solve this step by step.\\n<think>\"\n",
    "      }\n",
    "    ]\n",
    "    prompt = tokenizer.apply_chat_template(r1_prefix, tokenize=False, continue_final_message=True)\n",
    "    return {\"prompt\": prompt, \"target\": example[\"target\"], \"nums\": example[\"nums\"]}\n",
    "\n",
    "dataset = dataset.map(generate_r1_prompt)\n",
    "\n",
    "# Split dataset into train and test sets.\n",
    "split_dataset = dataset.train_test_split(test_size=0.1)\n",
    "train_dataset = split_dataset[\"train\"]\n",
    "test_dataset = split_dataset[\"test\"]\n",
    "\n",
    "print(\"Data preprocessing complete. Train size:\", len(train_dataset), \"Test size:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/train_dataset.json\", \"w\") as f:\n",
    "    json.dump(train_dataset.to_dict(), f)\n",
    "with open(\"data/test_dataset.json\", \"w\") as f:\n",
    "    json.dump(train_dataset.to_dict(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def format_reward_func(completions, target, **kwargs):\n",
    "    \"\"\"\n",
    "    Checks for proper format: <think>...</think>\\n<answer>...</answer>\n",
    "    \"\"\"\n",
    "    rewards = []\n",
    "    for completion, gt in zip(completions, target):\n",
    "        try:\n",
    "            # Add synthetic <think> tag as it prefaces the assistant's output.\n",
    "            completion = \"<think>\" + completion  \n",
    "            regex = r\"^<think>([^<]*(?:<(?!/?think>)[^<]*)*)<\\/think>\\n<answer>([\\s\\S]*?)<\\/answer>$\"\n",
    "            match = re.search(regex, completion, re.DOTALL)\n",
    "            if match is None or len(match.groups()) != 2:\n",
    "                rewards.append(0.0)\n",
    "            else:\n",
    "                rewards.append(1.0)\n",
    "        except Exception:\n",
    "            rewards.append(0.0)\n",
    "    return rewards\n",
    "\n",
    "def equation_reward_func(completions, target, nums, **kwargs):\n",
    "    \"\"\"\n",
    "    Evaluates correctness of the equation in the output.\n",
    "    \"\"\"\n",
    "    rewards = []\n",
    "    for completion, gt, numbers in zip(completions, target, nums):\n",
    "        try:\n",
    "            completion = \"<think>\" + completion\n",
    "            match = re.search(r\"<answer>(.*?)<\\/answer>\", completion)\n",
    "            if match is None:\n",
    "                rewards.append(0.0)\n",
    "                continue\n",
    "            equation = match.group(1).strip()\n",
    "            # Extract and compare used numbers.\n",
    "            used_numbers = [int(n) for n in re.findall(r'\\d+', equation)]\n",
    "            if sorted(used_numbers) != sorted(numbers):\n",
    "                rewards.append(0.0)\n",
    "                continue\n",
    "            allowed_pattern = r'^[\\d+\\-*/().\\s]+$'\n",
    "            if not re.match(allowed_pattern, equation):\n",
    "                rewards.append(0.0)\n",
    "                continue\n",
    "            result = eval(equation, {\"__builtins__\": None}, {})\n",
    "            if abs(float(result) - float(gt)) < 1e-5:\n",
    "                rewards.append(1.0)\n",
    "            else:\n",
    "                rewards.append(0.0)\n",
    "        except Exception:\n",
    "            rewards.append(0.0)\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) Run quick tests on the reward functions here if desired.\n",
    "correct_sample_1 = \"\"\"We need to find an equation using the numbers 19, 36, 55, and 7\n",
    "exactly once, with basic arithmetic operations, that equals 65. One possible\n",
    "combination is 55 + 36 - 19 + 7... </think>\n",
    "<answer> 55 + 36 - 7 - 19 </answer>\"\"\"\n",
    " \n",
    "correct_sample_2 = \"\"\" ... </think>\n",
    "<answer> 55 + 36 - 7 - 19 </answer>\"\"\"\n",
    " \n",
    "wrong_format = \"\"\"User: Using the numbers [19, 36, 55, 7], create an equation that equals 65.\"\"\"\n",
    " \n",
    "wrong_format_2 = \"\"\"To find the equation that equals 79 using the numbers 95, 78, 6, 88, I'll start by adding 88 and 95:                      \n",
    "95 + 88 = 183                                                                                                              \n",
    "Now, let's subtract 104 from 183 to get 79:\n",
    "183 - 104 = 79\n",
    "<think> 183 - 104 = 79 </think><think> 183 - 104 = 79 </think><answer> 183 - 104 = 79 </answer>\"\"\"\n",
    " \n",
    "wrong_result = \"\"\" ... </think>\n",
    "<answer> 55 + 36 - 7 - 18 </answer>\"\"\"\n",
    " \n",
    " \n",
    "test_rewards = format_reward_func(completions=[correct_sample_1, correct_sample_2, wrong_format, wrong_format_2, wrong_result], target=[\"65\", \"65\", \"65\", \"65\", \"65\"], nums=[[19, 36, 55, 7]] * 5)\n",
    "assert test_rewards == [1.0, 1.0, 0.0, 0.0, 1.0], \"Reward function is not working\"\n",
    "test_rewards = equation_reward_func(completions=[correct_sample_1, correct_sample_2, wrong_format, wrong_format_2, wrong_result], target=[\"65\", \"65\", \"65\", \"65\", \"65\"], nums=[[19, 36, 55, 7]] * 5)\n",
    "assert test_rewards == [1.0, 1.0, 0.0, 0.0, 0.0], \"Reward function is not working\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with Modal\n",
    "- [Modal](https://modal.com/): [Docs](https://modal.com/docs)  |  [Logs](https://modal.com/logs)  |  [Github](https://github.com/modal-labs/modal-client)  |  [Notebook Example](https://modal.com/docs/guide/notebooks)\n",
    "- Follow [this guide](https://modal.com/docs/guide) to create and connect an account on Modal\n",
    "- In [Modal Secrets](https://modal.com/secrets), add a HuggingFace secret (HF_SECRET) with your HuggingFace token (HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modal\n",
    "\n",
    "app = modal.App()\n",
    "\n",
    "image = (  \n",
    "    modal.Image.from_registry(\"nvidia/cuda:12.2.2-cudnn8-devel-ubuntu22.04\", add_python=\"3.11\")\n",
    "    .apt_install(\"git\", \"cmake\", \"clang\", \"build-essential\", \"libgomp1\")\n",
    "    .run_commands(\n",
    "        \"git config --global credential.helper store\",\n",
    "        \"git config --global --add safe.directory '*'\"\n",
    "    )\n",
    "    # .entrypoint([])\n",
    "    .pip_install(\n",
    "        \"torch==2.5.1\", \n",
    "        \"tensorboard\", \n",
    "        \"setuptools<71.0.0\",\n",
    "        \"huggingface_hub\",\n",
    "        \"trl==0.14.0\",\n",
    "        \"bitsandbytes\",\n",
    "        \"ninja\",\n",
    "        \"peft\",\n",
    "        \"transformers==4.48.1\",\n",
    "        \"accelerate==1.3.0\",\n",
    "        \"hf-transfer==0.1.9\",\n",
    "        \"deepspeed==0.15.4\",\n",
    "        \"vllm==0.7.0\",\n",
    "        \"datasets\",\n",
    "    )\n",
    "    .pip_install(\"flash-attn==2.5.8\") #, extra_options=\"--no-build-isolation\")\n",
    "    .env({\"HF_HUB_ENABLE_HF_TRANSFER\": \"1\"})\n",
    "    .add_local_dir(\"data\", remote_path=\"/mnt/data\")\n",
    ")\n",
    "\n",
    "@app.function(image=image, \n",
    "              gpu=\"A100\", \n",
    "              secrets=[modal.Secret.from_name(\"HF_SECRET\")],\n",
    "              timeout=20 * 60 * 60,  # 20 hours\n",
    "              )\n",
    "def train_model():\n",
    "    # Import modules inside the function so they load from the Modal image.\n",
    "    import os\n",
    "    from huggingface_hub import login\n",
    "    from datasets import Dataset\n",
    "    login(token=os.environ[\"HF_TOKEN\"], add_to_git_credential=True)\n",
    "    print(\"Logged into HF Hub in remote training function.\")\n",
    "    \n",
    "    import json\n",
    "    # Import TRL and related modules inside the function.\n",
    "    from trl import GRPOConfig, GRPOTrainer, get_peft_config, ModelConfig\n",
    "\n",
    "    # Load the datasets from the mounted directory.\n",
    "    with open(\"/mnt/data/train_dataset.json\") as f:\n",
    "        train_dataset = Dataset.from_dict(json.load(f))\n",
    "    with open(\"/mnt/data/test_dataset.json\") as f:\n",
    "        test_dataset = Dataset.from_dict(json.load(f))\n",
    "    print(\"Loaded datasets.\")\n",
    "    # Define the model's configuration.\n",
    "    model_config = ModelConfig(\n",
    "        model_name_or_path=\"Qwen/Qwen2.5-3B-Instruct\",\n",
    "        torch_dtype=\"bfloat16\",\n",
    "        attn_implementation=\"flash_attention_2\",\n",
    "        use_peft=True,\n",
    "        load_in_4bit=True,\n",
    "    )\n",
    "    print(\"Build model config.\")\n",
    "    # Specify GRPO training hyperparameters.\n",
    "    training_args = GRPOConfig(\n",
    "        output_dir=\"qwen-r1-aha-moment\",\n",
    "        learning_rate=5e-7,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        logging_steps=10,\n",
    "        max_steps=100,  # Example: Increase for real training.\n",
    "        per_device_train_batch_size=1,\n",
    "        gradient_accumulation_steps=1,\n",
    "        gradient_checkpointing=True,\n",
    "        gradient_checkpointing_kwargs={\"use_reentrant\": False},\n",
    "        bf16=True,\n",
    "        max_prompt_length=256,\n",
    "        max_completion_length=1024,\n",
    "        num_generations=2,\n",
    "        beta=0.001,\n",
    "    )\n",
    "\n",
    "    # Initialize the GRPO trainer.\n",
    "    trainer = GRPOTrainer(\n",
    "        model=model_config.model_name_or_path,\n",
    "        reward_funcs=[format_reward_func, equation_reward_func],\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        peft_config=get_peft_config(model_config),\n",
    "    )\n",
    "\n",
    "    print(\"Starting training on remote GPU...\")\n",
    "    trainer.train()\n",
    "    trainer.save_model(training_args.output_dir)\n",
    "    print(\"Training complete; model saved to:\", training_args.output_dir)\n",
    "    return \"Training complete!\"\n",
    "\n",
    "with app.run():\n",
    "    result = train_model.remote()\n",
    "    print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
